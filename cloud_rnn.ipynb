{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ba80c2-a75d-48cb-8d37-f13309331ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "# from tokenization import return_tokens\n",
    "# from julia import Main\n",
    "import h5py\n",
    "import hdf5plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e0721b-cf79-4918-a6ae-4884e896faa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.list_physical_devices('GPU')\n",
    "\n",
    "# https://stackoverflow.com/questions/41402409/tensorflow-doesnt-seem-to-see-my-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd6f58e-045e-491b-ab0d-2d57853fe077",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(f'{os.getcwd()}//augmented_data.jld', 'r')\n",
    "X = np.array(f['X'])\n",
    "X = np.transpose(X)\n",
    "Y = np.array(f['Y'])\n",
    "Y = np.transpose(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f04977-a83e-44ca-b100-f98f161dc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 60_000\n",
    "\n",
    "indicies = pd.DataFrame(range(len(X)), columns=['i'])\n",
    "indicies = indicies['i'].sample(n=n).to_numpy()\n",
    "\n",
    "sampled_X = np.zeros((n, X.shape[1], X.shape[2]))\n",
    "sampled_Y = np.zeros((n, Y.shape[1]))\n",
    "\n",
    "for n, i in enumerate(indicies):\n",
    "    sampled_X[n] = X[i]\n",
    "    sampled_Y[n] = Y[i]\n",
    "\n",
    "print(np.average([np.argmax(i) for i in sampled_Y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b13b339c-0798-4be0-8d8a-b7aefc7f82e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54000, 190, 72), (6000, 190, 72), (54000, 2), (6000, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=.1)\n",
    "trainX.shape, testX.shape, trainY.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f874cae2-e57d-4d0b-ad48-d9d9e49b5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(.0001)\n",
    "input_shape = trainX[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0829ee8-3764-4d41-a73f-63e35cf17a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 190, 128)          102912    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 190, 128)          131584    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 286,546\n",
      "Trainable params: 286,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(514, input_shape=input_shape, activation=\"tanh\", return_sequences=True, dropout=0.2)) \n",
    "model.add(LSTM(256, activation=\"tanh\", return_sequences=True, dropout=0.2))\n",
    "model.add(LSTM(128, activation=\"tanh\", dropout=0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a3be05e-d205-4ee7-b35e-eb56b00cb73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6036a0-f011-4af1-9d59-d10ae4b424fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1688/1688 [==============================] - 319s 189ms/step - loss: 0.6477 - accuracy: 0.6236 - val_loss: 0.6227 - val_accuracy: 0.6507\n",
      "Epoch 2/100\n",
      "1688/1688 [==============================] - 304s 180ms/step - loss: 0.6293 - accuracy: 0.6484 - val_loss: 0.5950 - val_accuracy: 0.6747\n",
      "Epoch 3/100\n",
      "1688/1688 [==============================] - 301s 178ms/step - loss: 0.6188 - accuracy: 0.6586 - val_loss: 0.5758 - val_accuracy: 0.7028\n",
      "Epoch 4/100\n",
      "1688/1688 [==============================] - 299s 177ms/step - loss: 0.6081 - accuracy: 0.6690 - val_loss: 0.5702 - val_accuracy: 0.7135\n",
      "Epoch 5/100\n",
      "1688/1688 [==============================] - 297s 176ms/step - loss: 0.6000 - accuracy: 0.6766 - val_loss: 0.5627 - val_accuracy: 0.7020\n",
      "Epoch 6/100\n",
      "1688/1688 [==============================] - 297s 176ms/step - loss: 0.5951 - accuracy: 0.6822 - val_loss: 0.5582 - val_accuracy: 0.7097\n",
      "Epoch 7/100\n",
      "1688/1688 [==============================] - 297s 176ms/step - loss: 0.5899 - accuracy: 0.6866 - val_loss: 0.5464 - val_accuracy: 0.7235\n",
      "Epoch 8/100\n",
      "1688/1688 [==============================] - 297s 176ms/step - loss: 0.5850 - accuracy: 0.6915 - val_loss: 0.5465 - val_accuracy: 0.7287\n",
      "Epoch 9/100\n",
      "1688/1688 [==============================] - 298s 176ms/step - loss: 0.5822 - accuracy: 0.6931 - val_loss: 0.5423 - val_accuracy: 0.7312\n",
      "Epoch 10/100\n",
      "1688/1688 [==============================] - 297s 176ms/step - loss: 0.5763 - accuracy: 0.6994 - val_loss: 0.5404 - val_accuracy: 0.7348\n",
      "Epoch 11/100\n",
      "1688/1688 [==============================] - 297s 176ms/step - loss: 0.5725 - accuracy: 0.7040 - val_loss: 0.5280 - val_accuracy: 0.7392\n",
      "Epoch 12/100\n",
      "1688/1688 [==============================] - 296s 176ms/step - loss: 0.5691 - accuracy: 0.7066 - val_loss: 0.5430 - val_accuracy: 0.7388\n",
      "Epoch 13/100\n",
      "1688/1688 [==============================] - 297s 176ms/step - loss: 0.5671 - accuracy: 0.7074 - val_loss: 0.5298 - val_accuracy: 0.7390\n",
      "Epoch 14/100\n",
      "1688/1688 [==============================] - 297s 176ms/step - loss: 0.5615 - accuracy: 0.7128 - val_loss: 0.5227 - val_accuracy: 0.7420\n",
      "Epoch 15/100\n",
      " 722/1688 [===========>..................] - ETA: 2:43 - loss: 0.5582 - accuracy: 0.7164"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, batch_size=32, epochs=100, validation_data=(testX, testY), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b040e-ade1-475d-aea1-eef96987a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_df.to_csv(f'{os.getcwd()}//model_history.csv')\n",
    "model.save(f'{os.getcwd()}//rnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGen(tf.keras.utils.Sequence) :\n",
    "    def __init__(self, X, Y, batch_size, length=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.batch_size = batch_size\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.length is None:\n",
    "            self.length = len(X)\n",
    "\n",
    "        return int(self.length / self.batch_size)\n",
    "        \n",
    "    def __getitem__(self, idx) :\n",
    "        # xfile, yfile = self.filenames\n",
    "\n",
    "        # xdf = pd.read_csv(xfile, sep=\"&\", skiprows=idx*self.batch_size, nrows=self.batch_size, header=None)\n",
    "        # xdf.columns = ['X']\n",
    "        # ydf = pd.read_csv(yfile, skiprows=idx*self.batch_size, nrows=self.batch_size, header=None)\n",
    "        # ydf.columns = ['Y']\n",
    "\n",
    "        # if self.x_size == None:\n",
    "        #     self.x_size = len(ast.literal_eval(xdf.iloc[0, 0]))\n",
    "\n",
    "        # x = np.zeros((self.batch_size, self.x_size)) # must be seq length or len(ast.literal_eval(xdf[0][0])))\n",
    "        # for n, i in enumerate(xdf.iloc[:, 0]):\n",
    "        #     i = np.array(ast.literal_eval(i)) / len(char_to_int)\n",
    "        #     x[n] = i\n",
    "\n",
    "        # ys = np.array(ydf.iloc[:, 0])\n",
    "        # one_hot_encoding = np.zeros((len(char_to_int)))\n",
    "\n",
    "        # y = np.zeros((len(ydf.iloc[:, 0]), len(one_hot_encoding)))\n",
    "        # for n, i in enumerate(ys):\n",
    "        #     temp = one_hot_encoding\n",
    "        #     temp[ys[n]] = 1\n",
    "        #     y[n] = temp\n",
    "\n",
    "        x = self.X[idx:idx + self.batch_size]\n",
    "        y = self.Y[idx:idx + self.batch_size]\n",
    "\n",
    "        return (x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e49f74e46b456e49c6fe038b9d452af7a62c4b3c345dd5f08f3508413a9f0789"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
