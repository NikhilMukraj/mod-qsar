{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "from smiles_tools import return_tokens, SmilesEnumerator\n",
    "from c_wrapper import seqOneHot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "vocab = pd.read_csv(f'{os.path.dirname(os.getcwd())}/preprocessor/vocab.csv')['tokens'].to_list()\n",
    "\n",
    "tokenizer = {i : n for n, i in enumerate(vocab)}\n",
    "reverse_tokenizer = {value: key for key, value in tokenizer.items()}\n",
    "convert_back = lambda x: ''.join(reverse_tokenizer.get(np.argmax(i)-1, '') for i in x)\n",
    "\n",
    "def augment_smiles(string, n):\n",
    "    sme = SmilesEnumerator()\n",
    "    output = []\n",
    "    for i in range(n):\n",
    "        output.append(sme.randomize_smiles(string))\n",
    "    \n",
    "    return output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "augment_smiles (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = py\"tokenizer\"\n",
    "reverse_tokenizer = py\"reverse_tokenizer\"\n",
    "convert_back = py\"convert_back\"\n",
    "return_tokens = py\"return_tokens\"\n",
    "\n",
    "augment_smiles(str, n) = py\"augment_smiles\"(str, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenize_and_pad (generic function with 2 methods)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function standardizeCase(str::String)\n",
    "    str = titlecase(str)\n",
    "    str = replace(str, \"h\" => \"H\")\n",
    "    return str\n",
    "end\n",
    "\n",
    "function return_augmented_list(str::String, n::Int64=5)\n",
    "    current_augmentation = Matrix{String}(undef, 0, 1)\n",
    "    counter = 0\n",
    "\n",
    "    while length(current_augmentation) < n && counter < n * 2\n",
    "        new_string = augment_smiles(str, 1)[begin]\n",
    "        current_tokens = standardizeCase.(return_tokens(new_string, py\"vocab\")[begin])\n",
    "        if issubset(Set(current_tokens), keys(tokenizer))\n",
    "            current_augmentation = vcat(current_augmentation, join(current_tokens))\n",
    "        end\n",
    "        counter += 1\n",
    "    end\n",
    "\n",
    "    return current_augmentation\n",
    "end\n",
    "\n",
    "function return_augmented_tokens(str::String, n::Int64=5)\n",
    "    current_augmentation = []\n",
    "    counter = 0\n",
    "\n",
    "    while length(current_augmentation) < n && counter < n * 2\n",
    "        new_string = augment_smiles(str, 1)[begin]\n",
    "        current_tokens = standardizeCase.(return_tokens(new_string, py\"vocab\")[begin])\n",
    "        if issubset(Set(current_tokens), keys(tokenizer))\n",
    "            push!(current_augmentation, current_tokens)\n",
    "        end\n",
    "        counter += 1\n",
    "    end\n",
    "\n",
    "    return current_augmentation\n",
    "end\n",
    "    \n",
    "function tokenize_and_pad(tokens_vector; max_len::Int64=190)\n",
    "    len = max_len - length(tokens_vector)\n",
    "    return vcat(zeros(Int, len), [tokenizer[i]+1 for i in tokens_vector])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(model, sample, shape; verbosity=0)\n",
    "    return py\"$(model).predict(np.array($(sample)).reshape($(shape)), verbose=0)\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Any}:\n",
       " Matrix{Int32}[[1 0 … 0 0; 1 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0], [1 0 … 0 0; 1 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0], [1 0 … 0 0; 1 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0], [1 0 … 0 0; 1 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0], [1 0 … 0 0; 1 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 372ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5×2 Matrix{Float32}:\n",
       " 0.0175267   0.982473\n",
       " 0.651568    0.348432\n",
       " 0.971154    0.0288456\n",
       " 0.00101979  0.99898\n",
       " 0.00186065  0.998139"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(py\"model\", seqs, [5, 190, 72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "augment_and_predict (generic function with 2 methods)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function augment_and_predict(strings, shape, models; n::Int64=5)\n",
    "    tokens = return_augmented_tokens.(strings, n)\n",
    "    indicies = [i for i in 1:length(tokens) if length(tokens[i]) == n]\n",
    "    \n",
    "    encoded_seqs = []\n",
    "    for i in 1:length(strings)\n",
    "        if i in indicies\n",
    "            push!(encoded_seqs, [py\"seqOneHot\"(tokenize_and_pad(j, max_len=shape[begin]), shape) for j in tokens[i]])\n",
    "        else\n",
    "            push!(encoded_seqs, [py\"seqOneHot\"(tokenize_and_pad(return_tokens(strings[i], py\"vocab\")[begin], max_len=shape[begin]), shape)])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    preds = [[] for i in 1:length(models)]\n",
    "    for (n, model) in enumerate(models)\n",
    "        for i in encoded_seqs\n",
    "            pred = predict(model, i, [length(i), shape...])\n",
    "            push!(preds[n], pred)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return [[argmax(sum(eachrow(i)))-1 for i in j] for j in preds]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.load_model(f'{os.getcwd()}//dopa_rnn_model.h5')\n",
    "model.compile()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 332ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5×2 Matrix{Float32}:\n",
       " 0.202561  0.797439\n",
       " 0.26447   0.73553\n",
       " 0.808269  0.191731\n",
       " 0.557924  0.442076\n",
       " 0.26121   0.73879"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = py\"model.predict(np.array($(seqs)).reshape(5, 190, 72))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Vector{Int64}}:\n",
       " [1]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment_and_predict([\"CC1CCN(CC1)CCCN2C(=O)C3=CC=CC=C3N=C2SCC(=O)NC4=C(C=C(C=C4)OC)OC\"], [190, 72], [py\"model\"], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
